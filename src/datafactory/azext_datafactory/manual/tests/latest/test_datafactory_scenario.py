# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------


# EXAMPLE: IntegrationRuntimes_Create
def step_integration_runtime_create(test, rg):
    test.cmd('az datafactory integration-runtime self-hosted create '
             '--factory-name "{myFactory}" '
             '--description "A selfhosted integration runtime" '
             '--name "{myIntegrationRuntime}" '
             '--resource-group "{rg}"',
             checks=[
                 test.check('name', "{myIntegrationRuntime}"),
                 test.check('properties.type', 'SelfHosted')
             ])


def step_trigger_run_rerun(test, rg):
    test.cmd('az datafactory trigger-run rerun '
             '--factory-name "{myFactory}" '
             '--resource-group "{rg}" '
             '--trigger-name "{myTrigger}" '
             '--run-id "{myRunId}"',
             checks=[])


def step_pipeline_create_run(test, rg):
    output = test.cmd('az datafactory pipeline create-run '
                      '--factory-name "{myFactory}" '
                      '--parameters "{{\\"OutputBlobNameList\\":[\\"exampleoutput.csv\\"]}}" '
                      '--name "{myPipeline}" '
                      '--resource-group "{rg}"',
                      checks=[]).get_output_in_json()
    return output


def step_pipeline_run_cancel(test, rg):
    test.cmd('az datafactory pipeline-run cancel '
             '--factory-name "{myFactory}" '
             '--resource-group "{rg}" '
             '--run-id "{myRunId}"',
             checks=[])


def step_pipeline_run_show(test, rg):
    test.cmd('az datafactory pipeline-run show '
             '--factory-name "{myFactory}" '
             '--resource-group "{rg}" '
             '--run-id "{myRunId}"',
             checks=[])


def step_pipeline_update(test, rg):
    test.cmd('az datafactory pipeline update '
             '--factory-name "{myFactory}" '
             '--description "Test Update description" '
             '--name "{myPipeline}" '
             '--resource-group "{rg}"',
             checks=[])


def step_trigger_run_query_by_factory(test, rg):
    output = test.cmd('az datafactory trigger-run query-by-factory '
                      '--factory-name "{myFactory}" '
                      '--last-updated-after "{myStartTime}" '
                      '--last-updated-before "{myEndTime}" '
                      '--resource-group "{rg}"',
                      checks=[]).get_output_in_json()
    return output


def step_integration_runtime_managed_create(test, rg):
    test.cmd('az datafactory integration-runtime managed create '
             '--factory-name "{myFactory}" '
             '--name "{myIntegrationRuntime}" '
             '--resource-group "{rg}" '
             '--description "Managed Integration Runtime" '
             '--compute-properties "{{\\"location\\":'
             '\\"East US 2\\",\\"nodeSize\\":\\"Standard_D2_v3\\",'
             '\\"numberOfNodes\\":1,\\"maxParallelExecutionsPerNode\\":2}}" '
             '--ssis-properties "{{\\"edition\\":\\"Standard'
             '\\",\\"licenseType\\":\\"LicenseIncluded\\"}}" ',
             checks=[
                 test.check('name', "{myIntegrationRuntime}"),
                 test.check('properties.type', "Managed")
             ])


def step_pipeline_wait_create(test, rg):
    test.cmd('az datafactory pipeline create '
             '--factory-name "{myFactory}" '
             '--pipeline "{{\\"activities\\":[{{\\"name\\":\\"Wait1\\",'
             '\\"type\\":\\"Wait\\",\\"dependsOn\\":[],\\"userProperties'
             '\\":[],\\"typeProperties\\":{{\\"waitTimeInSeconds\\":5'
             '}}}}],\\"annotations\\":[]}}" '
             '--name "{myPipeline}" '
             '--resource-group "{rg}" ',
             checks=[
                 test.check('name', "{myPipeline}"),
                 test.check('activities[0].type', "Wait")
             ])


def step_trigger_tumble_create(test, rg):
    test.cmd('az datafactory trigger create '
             '--resource-group "{rg}" '
             '--properties "{{\\"description\\":\\"trumblingwindowtrigger'
             '\\",\\"annotations\\":[],\\"pipeline\\":{{\\"pipelineReference'
             '\\":{{\\"referenceName\\":\\"{myPipeline}\\",\\"type\\":'
             '\\"PipelineReference\\"}}}},\\"type\\":\\"TumblingWindowTrigger'
             '\\",\\"typeProperties\\":{{\\"frequency\\":\\"Minute\\",'
             '\\"interval\\":5,\\"startTime\\":\\"{myStartTime}\\",'
             '\\"endTime\\":\\"{myEndTime}\\",\\"delay\\":\\"00:00:00\\",'
             '\\"maxConcurrency\\":50,\\"retryPolicy\\":{{\\"intervalInSeconds'
             '\\":30}},\\"dependsOn\\":[]}}}}" '
             '--factory-name "{myFactory}" '
             '--name "{myTrigger}"',
             checks=[
                 test.check('name', "{myTrigger}"),
                 test.check('properties.type', "TumblingWindowTrigger"),
                 test.check('properties.pipeline.pipelineReference.referenceName',
                            "{myPipeline}")
             ])


def call_managed_integrationruntime_scenario(test, rg):
    from ....tests.latest import test_datafactory_scenario as g
    g.setup_scenario(test, rg)
    g.step_create(test, rg)
    step_integration_runtime_managed_create(test, rg)
    g.step_integration_runtime_show(test, rg)
    test.kwargs.update({'myIntegrationRuntime2': test.kwargs.get('myIntegrationRuntime')})
    g.step_integration_runtime_start(test, rg)
    g.step_integration_runtime_stop(test, rg)
    g.step_integration_runtime_delete(test, rg)
    g.step_delete(test, rg)
    g.cleanup_scenario(test, rg)


def call_triggerrun_scenario(test, rg):
    from ....tests.latest import test_datafactory_scenario as g
    import time
    g.setup_scenario(test, rg)
    g.step_create(test, rg)
    step_pipeline_wait_create(test, rg)
    createrun_res = step_pipeline_create_run(test, rg)
    time.sleep(5)
    test.kwargs.update({'myRunId': createrun_res.get('runId')})
    step_pipeline_run_show(test, rg)
    g.step_activity_run_query_by_pipeline_run(test, rg)
    createrun_res = step_pipeline_create_run(test, rg)
    test.kwargs.update({'myRunId': createrun_res.get('runId')})
    step_pipeline_run_cancel(test, rg)
    step_trigger_tumble_create(test, rg)
    g.step_trigger_start(test, rg)
    g.step_trigger_show(test, rg)
    maxRound = 2
    while True:
        triggerrun_res = step_trigger_run_query_by_factory(test, rg)
        if len(triggerrun_res['value']) > 0 and triggerrun_res['value'][0]['status'] == 'Succeeded':
            test.kwargs.update({'myRunId': triggerrun_res['value'][0]['triggerRunId']})
            break
        else:
            if maxRound > 0:
                maxRound -= 1
                print("waiting round: " + str(5 - maxRound))
                time.sleep(300)
            else:
                break
    if maxRound > 0:
        step_trigger_run_rerun(test, rg)
    step_trigger_run_query_by_factory(test, rg)
    g.step_trigger_stop(test, rg)
    g.step_trigger_delete(test, rg)
    g.step_pipeline_delete(test, rg)
    g.step_delete(test, rg)
    g.cleanup_scenario(test, rg)


def call_main_scenario(test, rg):
    from ....tests.latest import test_datafactory_scenario as g
    g.setup_scenario(test, rg)
    g.step_create(test, rg)
    g.step_update(test, rg)
    g.step_linked_service_create(test, rg)
    g.step_linked_service_update(test, rg)
    g.step_dataset_create(test, rg)
    g.step_dataset_update(test, rg)
    g.step_pipeline_create(test, rg)
    step_pipeline_update(test, rg)
    g.step_trigger_create(test, rg)
    g.step_trigger_update(test, rg)
    g.step_integration_runtime_self_hosted_create(test, rg)
    g.step_integration_runtime_update(test, rg)
    # g.step_integration_runtime_linked(test, rg)
    step_pipeline_create_run(test, rg)
    g.step_integration_runtime_show(test, rg)
    g.step_linked_service_show(test, rg)
    g.step_pipeline_show(test, rg)
    g.step_dataset_show(test, rg)
    g.step_trigger_show(test, rg)
    g.step_integration_runtime_list(test, rg)
    g.step_linked_service_list(test, rg)
    g.step_pipeline_list(test, rg)
    g.step_trigger_list(test, rg)
    g.step_dataset_list(test, rg)
    g.step_show(test, rg)
    g.step_list2(test, rg)
    g.step_list(test, rg)
    g.step_integration_runtime_regenerate_auth_key(test, rg)
    # g.step_integration_runtime_get_connection_info(test, rg)
    g.step_integration_runtime_sync_credentials(test, rg)
    g.step_integration_runtime_get_monitoring_data(test, rg)
    g.step_integration_runtime_list_auth_key(test, rg)
    g.step_integration_runtime_remove_link(test, rg)
    g.step_integration_runtime_get_status(test, rg)
    # g.step_integration_runtime_start(test, rg)
    # g.step_integration_runtime_stop(test, rg)
    # g.step_integrationruntimes_createlinkedintegrationruntime(test, rg)
    g.step_trigger_get_event_subscription_status(test, rg)
    # g.step_activity_run_query_by_pipeline_run(test, rg)
    g.step_trigger_unsubscribe_from_event(test, rg)
    g.step_trigger_subscribe_to_event(test, rg)
    g.step_trigger_start(test, rg)
    g.step_trigger_stop(test, rg)
    # g.step_get_git_hub_access_token(test, rg)
    g.step_get_data_plane_access(test, rg)
    # g.step_pipeline_run_query_by_factory(test, rg)
    # g.step_pipeline_run_cancel(test, rg)
    step_trigger_run_query_by_factory(test, rg)
    g.step_configure_factory_repo(test, rg)
    g.step_integration_runtime_delete(test, rg)
    g.step_trigger_delete(test, rg)
    g.step_pipeline_delete(test, rg)
    g.step_dataset_delete(test, rg)
    g.step_linked_service_delete(test, rg)
    g.step_delete(test, rg)
    g.cleanup_scenario(test, rg)


def call_scenario(test, rg):
    from datetime import datetime, timedelta
    now = datetime.utcnow()
    startTime = now.strftime("%Y-%m-%dT%H:%M:%SZ")
    an_hour_later = now + timedelta(hours=1)
    endTime = an_hour_later.strftime("%Y-%m-%dT%H:%M:%SZ")
    test.kwargs.update({
        'myStartTime': startTime,
        'myEndTime': endTime
    })
    call_main_scenario(test, rg)
    call_managed_integrationruntime_scenario(test, rg)
    call_triggerrun_scenario(test, rg)
