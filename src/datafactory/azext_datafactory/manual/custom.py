# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------

from knack.util import CLIError
from knack.log import get_logger

DATA_FLOW_SUBTYPES = ["Flowlet", "MappingDataFlow", "WranglingDataFlow"]


def datafactory_create(
    client,
    resource_group_name,
    factory_name,
    if_match=None,
    location=None,
    public_network_access=None,
    tags=None,
    factory_vsts_configuration=None,
    factory_git_hub_configuration=None,
    global_parameters=None,
):
    from azext_datafactory.vendored_sdks.datafactory.models import FactoryIdentity
    from azext_datafactory.vendored_sdks.datafactory.models import FactoryIdentityType

    all_repo_configuration = []
    if factory_vsts_configuration is not None:
        all_repo_configuration.append(factory_vsts_configuration)
    if factory_git_hub_configuration is not None:
        all_repo_configuration.append(factory_git_hub_configuration)
    if len(all_repo_configuration) > 1:
        raise CLIError(
            "At most one of factory_vsts_configuration, factory_git_hub_configuration is needed for "
            "repo_configuration!"
        )
    repo_configuration = (
        all_repo_configuration[0] if len(all_repo_configuration) == 1 else None
    )
    factory = {}
    factory["location"] = location
    factory["tags"] = tags
    factory["repo_configuration"] = repo_configuration
    factory["global_parameters"] = global_parameters
    factory["encryption"] = {}
    if public_network_access is not None:
        factory["publicnetworkaccess"] = public_network_access
    factory["identity"] = FactoryIdentity(type=FactoryIdentityType.SYSTEM_ASSIGNED)
    return client.create_or_update(
        resource_group_name=resource_group_name,
        factory_name=factory_name,
        if_match=if_match,
        factory=factory,
    )


def datafactory_update(client, resource_group_name, factory_name, public_network_access=None, tags=None):
    factory_update_parameters = {}
    factory_update_parameters["tags"] = tags
    if public_network_access is not None:
        factory_update_parameters["publicnetworkaccess"] = public_network_access
    return client.update(
        resource_group_name=resource_group_name,
        factory_name=factory_name,
        factory_update_parameters=factory_update_parameters,
    )


# Data Flows
def datafactory_data_flow_list(client, resource_group_name, factory_name):
    return client.list_by_factory(
        resource_group_name=resource_group_name, factory_name=factory_name
    )


def datafactory_data_flow_delete(
    client, resource_group_name, factory_name, data_flow_name
):
    return client.delete(
        resource_group_name=resource_group_name,
        factory_name=factory_name,
        data_flow_name=data_flow_name,
    )


def get_type_properties_from_properties(properties, create=True):
    logger = get_logger()
    type_properties_key = "typeProperties"
    sources_key = "sources"
    sources_value = []
    sinks_key = "sinks"
    sinks_value = []
    transformations_key = "transformations"
    transformations_value = []
    script_lines_key = "scriptLines"
    script_lines_value = []
    if not create:
        logger.warning(
            "If the definition is not correct here, the resource in ADF may be malformed"
        )
    if type_properties_key in properties.keys():
        logger.warning(
            'Any malformed "%s" sub-item will result in an '
            'incomplete definition once viewed on ADF.', type_properties_key
        )
        if ((sources_key in properties[type_properties_key].keys() or
             sinks_key in properties[type_properties_key].keys())
                and (script_lines_key not in properties[type_properties_key].keys())):
            logger.warning(
                "Not including a scriptLines in this case may result "
                "in a malformed data flow"
            )
        if sources_key in properties[type_properties_key].keys():
            sources_value = properties[type_properties_key][sources_key]
        if sinks_key in properties[type_properties_key].keys():
            sinks_value = properties[type_properties_key][sinks_key]
        if transformations_key in properties[type_properties_key].keys():
            transformations_value = properties[type_properties_key][transformations_key]
        if script_lines_key in properties[type_properties_key].keys():
            script_lines_value = properties[type_properties_key][script_lines_key]
    type_properties = {
        sources_key: sources_value,
        sinks_key: sinks_value,
        transformations_key: transformations_value,
        script_lines_key: script_lines_value
    }
    return type_properties


def datafactory_data_flow_create(
    client,
    resource_group_name,
    factory_name,
    data_flow_name,
    properties,
    flow_type,
    if_match=None,
):
    data_flow_properties = {}
    if flow_type not in DATA_FLOW_SUBTYPES:
        raise CLIError(
            f"Not a valid type of dataflow. Valid choices: {DATA_FLOW_SUBTYPES}"
        )

    data_flow_properties["type"] = flow_type
    data_flow_properties["description"] = (
        properties["description"] if "description" in properties.keys() else ""
    )
    data_flow_properties["folder"] = (
        {"name": properties["folder"]["name"]}
        if "folder" in properties.keys()
        else None
    )
    data_flow_properties["annotations"] = (
        properties["annotations"] if "annotations" in properties.keys() else []
    )
    data_flow_properties["typeProperties"] = (
        get_type_properties_from_properties(properties=properties, create=True)
    )
    data_flow = {"properties": data_flow_properties}
    return client.create_or_update(
        resource_group_name=resource_group_name,
        factory_name=factory_name,
        data_flow_name=data_flow_name,
        if_match=if_match,
        data_flow=data_flow,
    )


def datafactory_data_flow_update(
    client,
    resource_group_name,
    factory_name,
    data_flow_name,
    properties,
):
    data_flow_properties = {}
    # Avoid creating in the update command
    try:
        client.get(resource_group_name, factory_name, data_flow_name)
    except Exception as e:
        raise CLIError(
            f"No data flow with this name '{data_flow_name}' exists - no update performed"
        ) from e

    if "name" in properties.keys() and properties["name"] != data_flow_name:
        raise CLIError(
            "Do not update the name of the data flow via CLI - chance of naming collision"
        )
    if "type" not in properties.keys():
        raise CLIError(
            "Data flow type not defined in properties"
        )
    data_flow_properties["type"] = properties["type"]
    if "annotations" in properties.keys():
        data_flow_properties["annotations"] = properties["annotations"]
    if "description" in properties.keys():
        data_flow_properties["description"] = properties["description"]
    if "folder" in properties.keys():
        data_flow_properties["folder"] = {
            "name": properties["folder"]["name"]
        }
    data_flow_properties["typeProperties"] = (
        get_type_properties_from_properties(properties=properties, create=False)
    )
    data_flow_data = {"properties": data_flow_properties}
    return client.create_or_update(
        resource_group_name=resource_group_name,
        factory_name=factory_name,
        data_flow_name=data_flow_name,
        if_match=None,
        data_flow=data_flow_data,
    )
