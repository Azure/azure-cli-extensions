# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------
from unittest.mock import patch

import yaml
from azext_mlv2.tests.scenario_test_helper import MLBaseScenarioTest
from azure.ai.ml._scope_dependent_operations import OperationScope

import pytest


class K8SOnlineEndpointScenarioTest(MLBaseScenarioTest):
    def test_online_endpoint_k8s(self) -> None:
        endpoint_name_suffix = "-k8s"
        self.kwargs["online_endpoint_name"] = "{}{}".format(
            self.kwargs.get("onlineEndpointName", None), endpoint_name_suffix
        )
        cmd_create = self.cmd(
            "az ml online-endpoint create -n {online_endpoint_name} --file src/machinelearningservices/azext_mlv2/tests/test_configs/endpoints/online/online_endpoint_create_k8s.yml -g testrg -w testworkspace"
        )
        cmd_create = yaml.safe_load(cmd_create.output)
        assert cmd_create["name"] == self.kwargs.get("online_endpoint_name", None)
        assert cmd_create["auth_mode"] == "key"
        assert cmd_create["provisioning_state"] != ""
        assert cmd_create["compute"] != ""
        assert cmd_create["id"] is not None
        cmd_show = self.cmd("az ml online-endpoint show -n {online_endpoint_name} -g testrg -w testworkspace")
        cmd_show = yaml.safe_load(cmd_show.output)
        assert cmd_show["name"] == self.kwargs.get("online_endpoint_name", None)
        cmd_update = self.cmd("az ml online-endpoint update -n {online_endpoint_name}  --set tags.new_tag=new_val -g testrg -w testworkspace")
        cmd_update = yaml.safe_load(cmd_update.output)
        assert cmd_update["tags"]["new_tag"] == "new_val"
        cmd_delete = self.cmd("az ml online-endpoint delete -n {online_endpoint_name} --no-wait -y -g testrg -w testworkspace")
        assert cmd_delete.output == ""
        self.kwargs.pop("online_endpoint_name", None)

    def test_online_endpoint_k8s_set_compute(self) -> None:
        endpoint_name_suffix = "-k8s-2"
        self.kwargs["online_endpoint_name_2"] = "{}{}".format(
            self.kwargs.get("onlineEndpointName", None), endpoint_name_suffix
        )
        cmd_create = self.cmd(
            "az ml online-endpoint create -n {online_endpoint_name_2} --set compute=azureml:inferencecompute -g testrg -w testworkspace"
        )
        cmd_create = yaml.safe_load(cmd_create.output)
        assert cmd_create["name"] == self.kwargs.get("online_endpoint_name_2", None)
        assert cmd_create["auth_mode"] == "key"
        assert cmd_create["provisioning_state"] != ""
        assert "inferencecompute" in cmd_create["compute"]
        assert cmd_create["id"] is not None
        cmd_show = self.cmd("az ml online-endpoint show -n {online_endpoint_name_2} -g testrg -w testworkspace")
        cmd_show = yaml.safe_load(cmd_show.output)
        assert cmd_show["name"] == self.kwargs.get("online_endpoint_name_2", None)
        cmd_delete = self.cmd("az ml online-endpoint delete -n {online_endpoint_name_2} --no-wait -y -g testrg -w testworkspace")
        assert cmd_delete.output == ""
        self.kwargs.pop("online_endpoint_name_2", None)

    @pytest.mark.skip(reason="AKS legacy compute is not supported for online endpoints or deployments")
    def test_online_endpoint_k8s_deployment_cpu(self) -> None:
        endpoint_name_suffix = "-k8s-cpu"
        self.kwargs["online_endpoint_name_cpu"] = "{}{}".format(
            self.kwargs.get("onlineEndpointName", None), endpoint_name_suffix
        )
        self.kwargs["online_deployment_name_cpu"] = "{}{}".format(
            self.kwargs.get("onlineDeploymentName", None), endpoint_name_suffix
        )
        if not self.in_recording:
            patcher = patch.object(OperationScope, "resource_group_name", "000000000000000")
            patcher.start()

        # create endpoint with cpu instance type
        self.cmd(
            "az ml online-endpoint create -n {online_endpoint_name_cpu} --file src/machinelearningservices/azext_mlv2/tests/test_configs/endpoints/online/online_endpoint_create_k8s.yml -g testrg -w testworkspace"
        )

        # create deployment with unknown setting
        with pytest.raises(Exception):
            self.cmd(
                "az ml online-deployment create -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} --file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/online/online_deployment_blue.yaml --set unknown=value -g testrg -w testworkspace"
            )

        # create deployment with all traffic setting
        self.cmd(
            "az ml online-deployment create -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} --file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/online/online_deployment_blue.yaml --all-traffic -g testrg -w testworkspace"
        )

        # verify deployment settings
        deployment = self.cmd(
            "az ml online-deployment show -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} -g testrg -w testworkspace"
        )
        deployment = yaml.safe_load(deployment.output)
        scale_settings = {
            "type": "target_utilization",
            "max_instances": 1,
            "min_instances": 1,
            "polling_interval": 1,
            "target_utilization_percentage": 70,
        }
        assert deployment["scale_settings"] == scale_settings
        assert deployment["instance_type"] == "cpuinstance"
        assert deployment["type"] == "kubernetes"
        assert deployment["name"] == self.kwargs.get("online_deployment_name_cpu", None)
        assert deployment["endpoint_name"] == self.kwargs.get("online_endpoint_name_cpu", None)
        assert deployment["code_configuration"]
        assert deployment["model"]
        assert deployment["environment"]

        # assert traffic is 100
        endpoint = self.cmd("az ml online-endpoint show -n {online_endpoint_name_cpu} -g testrg -w testworkspace")
        endpoint = yaml.safe_load(endpoint.output)
        assert endpoint["traffic"] == {self.kwargs["online_deployment_name_cpu"]: 100}

        # invoke endpoint without deployment when traffic rule is set
        # comment this test out for bug: https://msdata.visualstudio.com/DefaultCollection/Vienna/_workitems/edit/1791755/
        """
        invoke_cmd = self.cmd(
           "az ml online-endpoint invoke --name {online_endpoint_name_cpu} -d {online_deployment_name_cpu} --request-file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/model-1/sample-request.json -g testrg -w testworkspace"
        )
        assert invoke_cmd.exit_code == 0
        result = yaml.safe_load(invoke_cmd.output)
        # check the invoke result
        assert result == "[5215.1981315798685, 3726.995485938578]"
        """

        # get logs
        logs = self.cmd(
            "az ml online-deployment get-logs -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} -g testrg -w testworkspace"
        )
        assert logs.exit_code == 0

        # can't delete deployment if traffic rule is not zero
        with pytest.raises(Exception):
            self.cmd("az ml online-deployment delete -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} -y -g testrg -w testworkspace")
        # update endpoint with set arguments: traffic to zero
        self.cmd('az ml online-endpoint update -n {online_endpoint_name_cpu} -r "{online_deployment_name_cpu}=0" -g testrg -w testworkspace')

        # assert traffic is 0
        endpoint = self.cmd("az ml online-endpoint show -n {online_endpoint_name_cpu} -g testrg -w testworkspace")
        endpoint = yaml.safe_load(endpoint.output)
        assert endpoint["traffic"] == {self.kwargs["online_deployment_name_cpu"]: 0}

        # invoke endpoint without deployment when traffic rule is zero
        # comment this out as this should throw exception, but no during the case autorun.
        # with pytest.raises(Exception):
        #    self.cmd(
        #        "az ml online-endpoint invoke -n {online_endpoint_name_cpu} --request-file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/model-1/sample-request.json -g testrg -w testworkspace"
        #    )

        # invoke endpoint with specific deployment
        # comment this test out for bug: https://msdata.visualstudio.com/DefaultCollection/Vienna/_workitems/edit/1791755/
        """
        invoke_cmd = self.cmd(
           "az ml online-endpoint invoke --name {online_endpoint_name_cpu} -d {online_deployment_name_cpu} --request-file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/model-1/sample-request.json -g testrg -w testworkspace"
        )
        assert invoke_cmd.exit_code == 0
        result = yaml.safe_load(invoke_cmd.output)
        check the invoke result
        assert result == "[5215.1981315798685, 3726.995485938578]"
        """

        # update deployment with set arguments: scale type to default
        # commet this test out for bug https://msdata.visualstudio.com/Vienna/_workitems/edit/1760899
        """
        self.cmd("az ml online-deployment update -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} --set instance_count=2 --set scale_settings.type=\"default\" -g testrg -w testworkspace")
        # assert scale type and instance count
        deployment = self.cmd("az ml online-deployment show -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} -g testrg -w testworkspace")
        deployment = yaml.safe_load(deployment.output)
        assert deployment["scale_settings"]["type"] == "default"
        assert deployment["instance_count"] == 2
        """
        # delete deployment as traffic rule is zero now
        self.cmd("az ml online-deployment delete -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} -y -g testrg -w testworkspace")

        # verify deployment has been deleted
        with pytest.raises(Exception) as exp:
            self.cmd("az ml online-deployment show -n {online_deployment_name_cpu} -e {online_endpoint_name_cpu} -g testrg -w testworkspace")

        # delete endpoint
        self.cmd("az ml online-endpoint delete -n {online_endpoint_name_cpu} -y -g testrg -w testworkspace")

        self.kwargs.pop("online_endpoint_name_cpu", None)
        self.kwargs.pop("online_deployment_name_cpu", None)

    @pytest.mark.skip(reason="AKS legacy compute is not supported for online endpoints or deployments")
    def test_online_endpoint_k8s_deployment_gpu(self) -> None:
        endpoint_name_suffix = "-k8s-gpu"
        self.kwargs["online_endpoint_name_gpu"] = "{}{}".format(
            self.kwargs.get("onlineEndpointName", None), endpoint_name_suffix
        )
        self.kwargs["online_deployment_name_gpu"] = "{}{}".format(
            self.kwargs.get("onlineDeploymentName", None), endpoint_name_suffix
        )
        # create endpoint with gpu instance type
        self.cmd(
            "az ml online-endpoint create -n {online_endpoint_name_gpu} --file src/machinelearningservices/azext_mlv2/tests/test_configs/endpoints/online/online_endpoint_create_k8s.yml -g testrg -w testworkspace"
        )

        # create deployment with yaml file
        self.cmd(
            "az ml online-deployment create -n {online_deployment_name_gpu} -e {online_endpoint_name_gpu} --file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/online/online_deployment_k8s.yaml -g testrg -w testworkspace"
        )

        cmd2 = "az ml online-deployment show -n {online_deployment_name_gpu} -e {online_endpoint_name_gpu} -g testrg -w testworkspace"
        onl_mgr_dpt_obj_show = self.cmd(cmd2)
        onl_mgr_dpt_obj_show = yaml.safe_load(onl_mgr_dpt_obj_show.output)
        assert onl_mgr_dpt_obj_show["instance_type"] == "gpuinstance"
        assert onl_mgr_dpt_obj_show["scale_settings"]["type"] == "default"
        assert onl_mgr_dpt_obj_show["instance_count"] == 1

        # update deployment with yaml file
        cmd3 = "az ml online-deployment update -n {online_deployment_name_gpu} -e {online_endpoint_name_gpu} --file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/online/online_deployment_k8s_1.yaml -g testrg -w testworkspace"
        self.cmd(cmd3)

        cmd4 = "az ml online-deployment show -n {online_deployment_name_gpu} -e {online_endpoint_name_gpu} -g testrg -w testworkspace"
        deployment = self.cmd(cmd4)
        deployment = yaml.safe_load(deployment.output)

        assert deployment["instance_type"] == "gpuinstance"
        assert deployment["name"] == self.kwargs.get("online_deployment_name_gpu", None)
        assert deployment["endpoint_name"] == self.kwargs.get("online_endpoint_name_gpu", None)
        assert deployment["code_configuration"]
        assert deployment["model"]
        assert deployment["environment"]
        assert deployment["tags"]["tag1"] == "deployment-tag1-value"
        scale_settings = {
            "type": "target_utilization",
            "max_instances": 3,
            "min_instances": 1,
            "polling_interval": 10,
            "target_utilization_percentage": 70,
        }
        assert deployment["scale_settings"] == scale_settings
        request_settings = {
            "request_timeout_ms": 3000,
            "max_concurrent_requests_per_instance": 1,
            "max_queue_wait_ms": 3000,
        }
        assert deployment["request_settings"] == request_settings
        probe_settings = {
            "initial_delay": 5,
            "period": 5,
            "timeout": 10,
            "success_threshold": 1,
            "failure_threshold": 1,
        }
        assert deployment["liveness_probe"] == probe_settings
        assert deployment["readiness_probe"] == probe_settings
        resource_settings = {
            "requests": {"cpu": "0.1", "memory": "0.100Gi"},
            "limits": {"cpu": "0.2", "memory": "0.195Gi"},
        }
        assert deployment["resources"] == resource_settings

        self.cmd("az ml online-endpoint delete -n {online_endpoint_name_gpu} --no-wait -y -g testrg -w testworkspace")

        self.kwargs.pop("online_endpoint_name_gpu", None)
        self.kwargs.pop("online_deployment_name_gpu", None)

    @pytest.mark.skip(reason="TODO: 1887461, could not re-record this test due to regression")
    def test_online_endpoint_k8s_deployment_update(self) -> None:
        endpoint_name_suffix = "-k8s-gpu2"
        self.kwargs["online_endpoint_name_update"] = "{}{}".format(
            self.kwargs.get("onlineEndpointName", None), endpoint_name_suffix
        )
        self.kwargs["online_deployment_name_update"] = "{}{}".format(
            self.kwargs.get("onlineDeploymentName", None), endpoint_name_suffix
        )

        # create endpoint with gpu instance type
        self.cmd(
            "az ml online-endpoint create -n {online_endpoint_name_update} --file src/machinelearningservices/azext_mlv2/tests/test_configs/endpoints/online/online_endpoint_create_k8s.yml -g testrg -w testworkspace"
        )

        # create deployment with yaml file
        self.cmd(
            "az ml online-deployment create -n {online_deployment_name_update} -e {online_endpoint_name_update} --file src/machinelearningservices/azext_mlv2/tests/test_configs/deployments/online/online_deployment_k8s.yaml -g testrg -w testworkspace"
        )

        # update scale setting type to target utilization
        cmd1 = "az ml online-deployment update -n {online_deployment_name_update} -e {online_endpoint_name_update} --set scale_settings.type=target_utilization -g testrg -w testworkspace"
        self.cmd(cmd1)

        cmd2 = "az ml online-deployment show -n {online_deployment_name_update} -e {online_endpoint_name_update} -g testrg -w testworkspace"
        cmd2_show = self.cmd(cmd2)
        cmd2_show = yaml.safe_load(cmd2_show.output)
        assert cmd2_show["scale_settings"]["type"] == "target_utilization"

        # update scale setting type to default
        cmd3 = "az ml online-deployment update -n {online_deployment_name_update} -e {online_endpoint_name_update} --set scale_settings.type=default -g testrg -w testworkspace"
        self.cmd(cmd3)

        cmd4 = "az ml online-deployment show -n {online_deployment_name_update} -e {online_endpoint_name_update} -g testrg -w testworkspace"
        cmd4_show = self.cmd(cmd4)
        cmd4_show = yaml.safe_load(cmd4_show.output)
        assert cmd4_show["scale_settings"]["type"] == "default"

        self.cmd("az ml online-endpoint delete -n {online_endpoint_name_update} --no-wait -y -g testrg -w testworkspace")

        self.kwargs.pop("online_endpoint_name_update", None)
        self.kwargs.pop("online_deployment_name_update", None)


