# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------
import time
from typing import Dict

from knack.log import get_logger

from azure.ai.ml._utils._endpoint_utils import get_duration
from azure.ai.ml.entities._deployment.batch_deployment import BatchDeployment
from azure.ai.ml.entities._deployment.model_batch_deployment import ModelBatchDeployment
from azure.ai.ml.entities._deployment.pipeline_component_batch_deployment import PipelineComponentBatchDeployment
from azure.ai.ml.entities._load_functions import (
    load_batch_deployment, _try_load_yaml_dict, load_pipeline_component_batch_deployment,
    load_model_batch_deployment
)
from azure.ai.ml.constants._deployment import BatchDeploymentType
from azure.cli.core.commands import LongRunningOperation

from .raise_error import log_and_raise_error
from .utils import _dump_entity_with_warnings, get_ml_client

module_logger = get_logger(__name__)


def ml_batch_deployment_create(
    cmd,
    resource_group_name,
    workspace_name,
    file,
    endpoint_name=None,
    name=None,
    no_wait=False,
    set_default=False,
    params_override=None,
    skip_script_validation: bool = False,
    **kwargs,  # pylint: disable=unused-argument
):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )
    params_override = params_override or []

    yaml_dict = _try_load_yaml_dict(file)
    try:
        if name:
            params_override.append({"name": name})
        if endpoint_name:
            params_override.append({"endpoint_name": endpoint_name})
        if yaml_dict.get('type') == BatchDeploymentType.MODEL:
            deployment = load_model_batch_deployment(source=file, params_override=params_override)
        elif yaml_dict.get('type') == BatchDeploymentType.PIPELINE:
            deployment = load_pipeline_component_batch_deployment(source=file, params_override=params_override)
        else:
            deployment = load_batch_deployment(source=file, params_override=params_override)

        deployment_result = ml_client.begin_create_or_update(
            entity=deployment, skip_script_validation=skip_script_validation
        )
        if no_wait:
            module_logger.warning(
                "Batch deployment update/create request initiated. "
                "Status can be checked using `az ml batch-deployment show -e %s -n %s`\n",
                deployment.endpoint_name, deployment.name
            )
        else:
            deployment_result = LongRunningOperation(cmd.cli_ctx)(deployment_result)

        if set_default:
            endpoint = ml_client.batch_endpoints.get(deployment.endpoint_name)
            endpoint.defaults = {"deployment_name": deployment.name}
            endpoint = ml_client.begin_create_or_update(entity=endpoint)
            endpoint = LongRunningOperation(cmd.cli_ctx)(endpoint)
        return _dump_entity_with_warnings(deployment_result)
    except Exception as err:  # pylint: disable=broad-exception-caught
        yaml_operation = bool(file)
        log_and_raise_error(err, debug, yaml_operation=yaml_operation)


def ml_batch_deployment_show(cmd, resource_group_name, workspace_name, name, endpoint_name):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        deployment = ml_client.batch_deployments.get(name, endpoint_name)
        return _dump_entity_with_warnings(deployment)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_batch_deployment_delete(
    cmd,
    resource_group_name,
    workspace_name,
    name,
    endpoint_name,
    no_wait=False,
):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        start_time = time.time()
        result = ml_client.batch_deployments.begin_delete(name, endpoint_name)
        if no_wait:
            module_logger.warning(
                "Delete request initiated. Status can be checked using "
                "`az ml batch-deployment show -e %s -n %s`\n", endpoint_name, name
            )
        else:
            module_logger.warning("Deleting batch deployment %s ", name)
            result = LongRunningOperation(cmd.cli_ctx)(result)
            module_logger.warning("Done ")
            get_duration(start_time)
        return result
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_batch_deployment_list(cmd, resource_group_name, workspace_name, endpoint_name):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        return [
            _dump_entity_with_warnings(deployment)
            for deployment in ml_client.batch_deployments.list(endpoint_name)
        ]
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_batch_deployment_list_jobs(cmd, resource_group_name, workspace_name, name, endpoint_name):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        results = ml_client.batch_deployments.list_jobs(endpoint_name=endpoint_name, name=name)
        return [_dump_entity_with_warnings(deployment) for deployment in results]
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_batch_deployment_update(
    cmd,
    resource_group_name,
    workspace_name,
    no_wait=False,
    parameters: Dict = None,
    file=None,
):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    yaml_dict = _try_load_yaml_dict(file)
    try:
        if yaml_dict.get('type') == BatchDeploymentType.MODEL:
            deployment = ModelBatchDeployment._load(data=parameters, yaml_path=file)  # pylint: disable=protected-access
        elif yaml_dict.get('type') == BatchDeploymentType.PIPELINE:
            deployment = PipelineComponentBatchDeployment._load(data=parameters, yaml_path=file)  # pylint: disable=protected-access
        else:
            deployment = BatchDeployment._load(data=parameters, yaml_path=file)  # pylint: disable=protected-access
        deployment_result = ml_client.begin_create_or_update(entity=deployment)

        if no_wait:
            module_logger.warning(
                "Batch deployment update/create request initiated. "
                "Status can be checked using `az ml batch-deployment show -e %s -n %s`\n",
                deployment.endpoint_name, deployment.name
            )
        else:
            deployment_result = LongRunningOperation(cmd.cli_ctx)(deployment_result)
        if deployment_result:  # TODO: https://msdata.visualstudio.com/Vienna/_workitems/edit/1252491/
            return _dump_entity_with_warnings(deployment_result)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def _ml_batch_deployment_show(cmd, resource_group_name, workspace_name, name=None, endpoint_name=None, file=None):
    params_override = []
    if name:
        params_override.append({"name": name})

    if endpoint_name:
        params_override.append({"endpoint_name": endpoint_name})
    if file:
        yaml_dict = _try_load_yaml_dict(file)
        if yaml_dict.get('type') == BatchDeploymentType.MODEL:
            return load_model_batch_deployment(source=file, params_override=params_override)._to_dict()  # pylint: disable=protected-access
        if yaml_dict.get('type') == BatchDeploymentType.PIPELINE:
            return load_pipeline_component_batch_deployment(source=file, params_override=params_override)._to_dict()  # pylint: disable=protected-access
        return load_batch_deployment(file, params_override=params_override)._to_dict()  # pylint: disable=protected-access
    return ml_batch_deployment_show(cmd, resource_group_name, workspace_name, name, endpoint_name)
