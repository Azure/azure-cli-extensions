# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------
import os
import subprocess
from itertools import islice
from typing import Dict
from webbrowser import open_new_tab

from knack.log import get_logger
from marshmallow.utils import EXCLUDE

from azure.ai.ml.constants._common import MAX_LIST_CLI_RESULTS, CommonYamlFields
from azure.ai.ml.entities import Job
from azure.ai.ml.entities._builders.base_node import BaseNode
from azure.ai.ml.entities._load_functions import load_job
from azure.ai.ml.entities._validate_funcs import validate_job
from azure.ai.ml.exceptions import (
    ErrorCategory,
    ErrorTarget,
    PipelineChildJobError,
    ValidationErrorType,
    ValidationException,
)
from azure.cli.core import telemetry
from azure.cli.core.commands import LongRunningOperation
from azure.core.polling import LROPoller

from ._ssh_command import get_ssh_command, has_ssh_dependencies_installed, ssh_connector_file_path_space_message
from .raise_error import log_and_raise_error, print_limited_result_set_warning
from .utils import _dump_entity_with_warnings, filter_job_tags, get_list_view_type, get_ml_client

module_logger = get_logger(__name__)


def _dump_job_with_warnings(job: Job):
    if isinstance(job, BaseNode):
        job = job._to_job()  # pylint: disable=protected-access

    return _dump_entity_with_warnings(job)


def open_job_in_browser(job):
    try:
        studio_endpoint = None
        services = job.services
        if services:
            studio_endpoint = services.get("Studio", None)

        if studio_endpoint and studio_endpoint.endpoint:
            open_new_tab(studio_endpoint.endpoint)
        else:
            module_logger.warning("Option --web was specified, but no studio URI was found in the list of services.")

    except Exception as err:  # pylint: disable=broad-exception-caught
        module_logger.warning(err)


def ml_job_create(
    cmd,
    resource_group_name,
    workspace_name,
    file,
    name=None,
    save_as=None,
    stream=False,
    web=False,
    params_override=None,
    skip_validation=False,
):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )
    params_override = params_override or []

    try:
        if name is not None:
            params_override.append({"name": name})

        job = load_job(source=file, params_override=params_override)

        job = filter_job_tags(job)
        telemetry.set_debug_info("JobType", job.type)

        job = ml_client.jobs.create_or_update(job=job, skip_validation=skip_validation)
        if save_as:
            job.dump(save_as)

        if web:
            open_job_in_browser(job)

        if stream:
            ml_client.jobs.stream(name=job.name)

        return _dump_job_with_warnings(job)

    except Exception as err:  # pylint: disable=broad-exception-caught
        yaml_operation = bool(file)
        log_and_raise_error(err, debug, yaml_operation=yaml_operation)


def ml_job_validate(cmd, file, resource_group_name, workspace_name, params_override=None):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )
    params_override = params_override or []

    try:
        return _dump_entity_with_warnings(validate_job(path=file, ml_client=ml_client, params_override=params_override))
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_show(cmd, resource_group_name, workspace_name, name, web=False):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        job = ml_client.jobs.get(name)
        job = filter_job_tags(job)
        if web:
            open_job_in_browser(job)

        return _dump_job_with_warnings(job)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


# Used only by generic update to prevent the browser from opening when reading existing job if a user specifies "web"
def _ml_job_show(cmd, resource_group_name, workspace_name, name):
    return ml_job_show(cmd, resource_group_name, workspace_name, name)


def ml_job_show_services(cmd, resource_group_name, workspace_name, name, node_index=0):

    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        return ml_client.jobs.show_services(name, node_index)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_cancel(cmd, resource_group_name, workspace_name, name, no_wait=False):
    ml_job_cancel_private_preview(cmd, resource_group_name, workspace_name, name, no_wait=no_wait)


def ml_job_cancel_private_preview(cmd, resource_group_name, workspace_name, name, tag=None, no_wait=False):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        outcome = ml_client.jobs.begin_cancel(name, tag=tag)

        if not no_wait:
            if isinstance(outcome, LROPoller):
                return LongRunningOperation(cmd.cli_ctx)(outcome)
            if isinstance(outcome, list):
                # TODO: Any better Strategy to return List of LROPoller?
                return [LongRunningOperation(cmd.cli_ctx)(poller) for poller in outcome]
        return outcome
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_list_private_preview(
    cmd,
    resource_group_name,
    workspace_name,
    max_results=MAX_LIST_CLI_RESULTS,
    all_results=False,
    parent_job_name=None,
    include_archived=False,
    archived_only=False,
    **kwargs,  # pylint: disable=unused-argument
):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    if all_results:
        max_results = None
    else:
        print_limited_result_set_warning(max_results)

    try:
        ret_list = []
        list_view_type = get_list_view_type(include_archived=include_archived, archived_only=archived_only)
        if max_results:
            results = islice(
                ml_client.jobs.list(
                    parent_job_name=parent_job_name,
                    list_view_type=list_view_type,
                    max_results=max_results,
                ),
                int(max_results),
            )
        else:
            results = ml_client.jobs.list(
                parent_job_name=parent_job_name,
                list_view_type=list_view_type,
            )
        for job in results:
            job = filter_job_tags(job)
            ret_list.append(_dump_job_with_warnings(job))
        return ret_list
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_list(
    cmd,
    resource_group_name,
    workspace_name,
    max_results=MAX_LIST_CLI_RESULTS,
    all_results=False,
    parent_job_name=None,
    include_archived=False,
    archived_only=False,
    **kwargs,
):
    return ml_job_list_private_preview(
        cmd=cmd,
        resource_group_name=resource_group_name,
        workspace_name=workspace_name,
        max_results=max_results,
        all_results=all_results,
        parent_job_name=parent_job_name,
        include_archived=include_archived,
        archived_only=archived_only,
        **kwargs,
    )


def ml_job_download(cmd, resource_group_name, workspace_name, name, download_path=None,
                    output_name=None, all=False):  # pylint: disable=redefined-builtin

    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        if not download_path:
            download_path = cmd.cli_ctx.local_context.current_dir
        return ml_client.jobs.download(name=name, download_path=download_path, output_name=output_name, all=all)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_stream(cmd, resource_group_name, workspace_name, name):

    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        ml_client.jobs.stream(name=name)
    except PipelineChildJobError as err:
        log_and_raise_error(PipelineChildJobError(job_id=err.job_id, command="stream", prompt_studio_ui=True), debug)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_archive(cmd, resource_group_name, workspace_name, name):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )
    try:
        ml_client.jobs.archive(name=name)
    except PipelineChildJobError as err:
        log_and_raise_error(PipelineChildJobError(job_id=err.job_id, command="archive"), debug)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_restore(cmd, resource_group_name, workspace_name, name):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )
    try:
        ml_client.jobs.restore(name=name)
    except PipelineChildJobError as err:
        log_and_raise_error(PipelineChildJobError(job_id=err.job_id, command="restore"), debug)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


def ml_job_connect_ssh(cmd, resource_group_name, workspace_name, name, node_index=0, private_key_file_path=None):
    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        if private_key_file_path and not os.path.isfile(private_key_file_path):
            raise ValidationException(
                message="There is no file on target path: {}".format(private_key_file_path),
                target=ErrorTarget.JOB,
                no_personal_data_message="There is no file on target path",
                error_category=ErrorCategory.USER_ERROR,
                error_type=ValidationErrorType.FILE_OR_FOLDER_NOT_FOUND,
            )
        if not has_ssh_dependencies_installed():
            return

        services_dict = ml_client.jobs.show_services(name, node_index)
        path_has_space, ssh_command = get_ssh_command(services_dict, node_index, private_key_file_path)
        print(f"ssh_command: {ssh_command}")
        if path_has_space:
            module_logger.error(ssh_connector_file_path_space_message())
        else:
            subprocess.call(ssh_command, shell=True)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)


# This will only be used for generic update
def _ml_job_update(cmd, resource_group_name, workspace_name, web=False, parameters: Dict = None):

    ml_client, debug = get_ml_client(
        cli_ctx=cmd.cli_ctx, resource_group_name=resource_group_name, workspace_name=workspace_name
    )

    try:
        # hard code here to judge whether the passed in job is a child job
        if parameters.get(CommonYamlFields.TYPE) is None:
            raise PipelineChildJobError(job_id=parameters["id"].lstrip("azureml:"))  # remove leading "azureml:" in id

        # Set unknown to EXCLUDE so that marshmallow doesn't raise on dump only fields.
        job = Job._load(data=parameters, unknown=EXCLUDE)  # pylint: disable=protected-access

        updated_job = ml_client.jobs.create_or_update(job=job)
        updated_job = filter_job_tags(updated_job)
        if web:
            open_job_in_browser(updated_job)

        return _dump_job_with_warnings(updated_job)
    except PipelineChildJobError as err:
        log_and_raise_error(PipelineChildJobError(job_id=err.job_id, command="update", prompt_studio_ui=True), debug)
    except Exception as err:  # pylint: disable=broad-exception-caught
        log_and_raise_error(err, debug)
