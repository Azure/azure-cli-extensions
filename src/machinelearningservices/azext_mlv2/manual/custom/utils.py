# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------
# ---------------------------------------------------------
import json
import re
import sys
import traceback
from os import environ, getenv, pardir, path
from typing import Dict, Tuple, Union
from uuid import uuid4
from webbrowser import open_new_tab

from azext_mlv2.manual.user_agent import USER_AGENT
from azure.ai.ml import MLClient
from azure.ai.ml._azure_environments import _environments, _get_aml_resource_id_from_metadata, _get_default_cloud_name
from azure.ai.ml._restclient.v2020_09_01_dataplanepreview.models import BatchJobResource
from azure.ai.ml._restclient.v2022_02_01_preview.models import ListViewType
from azure.ai.ml._utils._storage_utils import AzureMLDatastorePathUri
from azure.ai.ml.constants._common import (
    ARM_ID_PREFIX,
    ASSET_ARM_ID_REGEX_FORMAT,
    ASSET_ID_REGEX_FORMAT,
    ASSET_ID_RESOURCE_REGEX_FORMAT,
    AZUREML_CLI_SYSTEM_EXECUTED_ENV_VAR,
    AZUREML_PRIVATE_FEATURES_ENV_VAR,
    DATA_ID_REGEX_FORMAT,
    MODEL_ID_REGEX_FORMAT,
    ArmConstants,
    AzureMLResourceType,
)
from azure.ai.ml.entities import Asset, AzureOpenAIDeployment, Job, MarketplaceSubscription, ServerlessEndpoint
from azure.ai.ml.entities._endpoint.online_endpoint import OnlineEndpoint
from azure.ai.ml.exceptions import (
    ErrorCategory,
    ErrorTarget,
    LocalEndpointNotFoundError,
    ValidationErrorType,
    ValidationException,
)
from azure.cli.core.commands import LongRunningOperation
from azure.cli.core.commands.client_factory import get_subscription_id
from azure.cli.core.telemetry import add_extension_event
from azure.core.exceptions import ResourceNotFoundError
from azure.core.polling import LROPoller
from knack.log import get_logger

from .raise_error import log_and_raise_error

module_logger = get_logger(__name__)


def _dump_entity_with_warnings(entity) -> Dict:
    if not entity:
        return
    if isinstance(entity, LROPoller):
        return entity
    if isinstance(entity, Dict):
        return entity
    try:
        if entity.__class__.__name__ == "ComponentContainerData" or isinstance(
            entity, (BatchJobResource, AzureOpenAIDeployment, ServerlessEndpoint, MarketplaceSubscription)
        ):
            return entity.as_dict()
        return entity._to_dict()  # type: ignore  # pylint: disable=protected-access
    except Exception as err:  # pylint: disable=broad-exception-caught
        module_logger.warning("Failed to deserialize response: %s", str(err))
        module_logger.warning(str(entity))
        module_logger.debug(traceback.format_exc())


def _is_debug_set(cli_context):
    return "--debug" in cli_context.data["safe_params"]


def check_private_feature_enabled_and_exit():
    if not private_features_enabled():
        log_and_raise_error("Specified operation is not supported.")


def private_features_enabled():
    return getenv(AZUREML_PRIVATE_FEATURES_ENV_VAR) in ["True", "true", True]


def get_user_agent():
    system_executed = get_cli_system_executed()
    user_agent = "{} {}".format(system_executed, USER_AGENT) if system_executed else USER_AGENT
    return user_agent


def get_cli_system_executed():
    return getenv(AZUREML_CLI_SYSTEM_EXECUTED_ENV_VAR)


def _get_ml_client(
    subscription_id,
    resource_group_name,
    workspace_name=None,
    registry_name=None,
    debug=False,
    cli_ctx=None,
    **kwargs,
) -> MLClient:
    from azure.cli.core.commands.client_factory import get_mgmt_service_client

    cloud_name = cli_ctx.cloud.name

    client_request_id = cli_ctx.data["headers"]["x-ms-client-request-id"] if cli_ctx else None

    kwargs_local = {
        "user_agent": get_user_agent(),
        "logging_enable": debug,
        "client_request_id": client_request_id,
        "workspace_name": workspace_name,
        "resource_group_name": resource_group_name,
        "registry_name": registry_name,
        "cloud": cloud_name,
    }
    kwargs.update(kwargs_local)

    if cloud_name is not None and cloud_name not in _environments:
        cloud_endpoints = cli_ctx.cloud.endpoints
        cloud_suffixes = cli_ctx.cloud.suffixes
        cloud_azure_portal_endpoint = cloud_endpoints.portal
        cloud_resource_manager_endpoint = cloud_endpoints.resource_manager
        cloud_active_directory_endpoint = cloud_endpoints.active_directory
        cloud_storage_endpoint = cloud_suffixes.storage_endpoint

        cloud_aml_resource_id = cloud_endpoints.portal.replace("portal", "ml")

        cloud_suffix = get_cloud_suffix_from_url(cloud_azure_portal_endpoint)
        cloud_registry_discovery_url = get_registry_discovery_url(cloud_name, cloud_suffix)

        kwargs_cloud = {
            "cloud_metadata": {
                "azure_portal": cloud_azure_portal_endpoint,
                "resource_manager": cloud_resource_manager_endpoint,
                "active_directory": cloud_active_directory_endpoint,
                "aml_resource_id": cloud_aml_resource_id,
                "storage_endpoint": cloud_storage_endpoint,
                "registry_discovery_url": cloud_registry_discovery_url,
            }
        }
        kwargs.update(kwargs_cloud)

    if client_request_id is None:
        client_request_id = str(uuid4())

    # This is to make sure service calls get the x-ms-client-request-id set by CLI
    # Useful for correlating CLI logs with service logs.
    # Removing or changing this will break the correlation.
    kwargs.update({"request_id": client_request_id})

    ml_client = get_mgmt_service_client(
        cli_ctx, MLClient._ml_client_cli, subscription_id=subscription_id, **kwargs  # pylint: disable=protected-access
    )

    return ml_client


def _get_cloud_information_from_cli(cli_ctx, **kwargs) -> Dict:
    cloud_name = cli_ctx.cloud.name
    management_hostname = cli_ctx.cloud.endpoints.resource_manager.strip("/")
    credential_scopes = [management_hostname + "/.default"]

    client_kwargs = {"cloud": cloud_name}

    if credential_scopes is not None:
        client_kwargs["credential_scopes"] = credential_scopes

    kwargs.update(client_kwargs)
    return kwargs


def get_ml_client(
    cli_ctx,
    resource_group_name: str = None,
    workspace_name: str = None,
    registry_name: str = None,
    **kwargs,
) -> Tuple[MLClient, bool]:
    subscription_id = get_subscription_id(cli_ctx)
    debug = _is_debug_set(cli_ctx)
    kwargs_cloud = _get_cloud_information_from_cli(cli_ctx=cli_ctx)
    kwargs.update(kwargs_cloud)

    registry_enabled_asset_type = (
        "ml environment" in cli_ctx.data["command"]
        or "ml model" in cli_ctx.data["command"]
        or "ml component" in cli_ctx.data["command"]
        or "ml data" in cli_ctx.data["command"]
    )
    verb = cli_ctx.data["command"].split(" ")[-1]
    registry_enabled_verb = verb in ["create", "list", "show"]

    if not registry_name and not workspace_name and registry_enabled_asset_type and registry_enabled_verb:
        missing_msg = "one the following arguments are required: [--workspace-name/-w, --registry-name]"
        raise ValidationException(
            message=missing_msg,
            no_personal_data_message=missing_msg,
            target=ErrorTarget.GENERAL,
            error_category=ErrorCategory.USER_ERROR,
            error_type=ValidationErrorType.MISSING_FIELD,
        )

    if registry_name and workspace_name:
        workspace_name = None

    ml_client = _get_ml_client(
        subscription_id=subscription_id,
        resource_group_name=resource_group_name,
        workspace_name=workspace_name,
        registry_name=registry_name,
        debug=debug,
        cli_ctx=cli_ctx,
        **kwargs,
    )
    return ml_client, debug


def reset_anonymous_asset(asset: Union[str, Asset]) -> None:
    if asset and isinstance(asset, Asset) and asset._is_anonymous:  # pylint: disable=protected-access
        asset.name = None
        asset.version = None


def validate_and_split_output_path(output_path: str) -> AzureMLDatastorePathUri:
    if output_path.startswith(ARM_ID_PREFIX):
        datastore_path = AzureMLDatastorePathUri(output_path)
        return datastore_path
    raise ValueError("Not a valid output_path, it should start with 'azureml:'")


def convert_str_to_dict(input_str: str) -> Dict[str, str]:
    return dict((x.strip(), y.strip()) for x, y in (ele.split("=") for ele in input_str.split(" ")))


def merged_nested_dictionaries(dictionaries: [Dict[str, str]]) -> [Dict[str, str]]:
    """
    Example: dictionaries = [{'inputs.key1.nestedKey1':'val1'}, {'inputs.key1.nestedKey2':'val2'},
    {'otherKey': 'newValue'}]
    merged_nested_dictionaries(dictionaries) =>
    [{'inputs': {key1: {'nestedKey': 'val1', 'nestedKey2':'val2'}}} , {'otherKey':'newValue'}]
    """
    res = {}
    for dictionary in dictionaries:
        for key, value in dictionary.items():
            keys = key.split(".")
            current_dict = res
            for key in keys[:-1]:
                if key not in current_dict:
                    current_dict[key] = {}
                current_dict = current_dict[key]
            current_dict[keys[-1]] = value
    result = []
    for key, val in res.items():
        result.append({key: val})
    return result


def filter_job_tags(job: Job):
    job.tags = {k: job.tags[k] for k in job.tags if "_aml_system_" not in k and "platform_config" not in k}
    return job


# Get values from nested dictionary safely.
def deep_get(d, keys, default=None):
    """
    Example:
        d = {'meta': {'status': 'OK', 'status_code': 200}}
        deep_get(d, ['meta', 'status_code'])          # => 200
        deep_get(d, ['missingkey', 'status_code'])       # => None
        deep_get(d, ['meta', 'missingkey'], default='-') # => '-'
    """
    assert isinstance(keys, list)
    if d is None:
        return default
    if not keys:
        return d
    return deep_get(d.get(keys[0]), keys[1:], default)


def get_list_view_type(include_archived: bool, archived_only: bool) -> ListViewType:
    if include_archived and archived_only:
        raise ValueError("Cannot provide both archived-only and include-archived.")
    if include_archived:
        return ListViewType.ALL
    if archived_only:
        return ListViewType.ARCHIVED_ONLY
    return ListViewType.ACTIVE_ONLY


def is_env_var_enabled(env_var_name):
    env_var = getenv(env_var_name)
    return env_var and env_var.lower() == "true"


def open_online_endpoint_in_browser(endpoint: OnlineEndpoint):
    resource_id = _get_aml_resource_id_from_metadata(_get_default_cloud_name())
    try:
        identity = endpoint.identity
        tenantId = identity.tenant_id
        name = endpoint.name
        endpoint_id = endpoint.id
        id_split = endpoint_id.split("/onlineEndpoints")
        wsid = id_split[0]
        uri = f"{resource_id}/endpoints/realtime/{name}/detail?wsid={wsid}&tid={tenantId}"
        open_new_tab(uri)
    except Exception as err:  # pylint: disable=broad-exception-caught
        module_logger.warning(err)


def is_not_found_error(ex: BaseException) -> bool:
    return isinstance(ex, LocalEndpointNotFoundError) or (
        isinstance(ex, ResourceNotFoundError) and ex.status_code == 404
    )


def wrap_lro(cli_ctx, maybe_lro):
    # This works around a bug in the SDK. Online endpoint/deployment operations have changed the type of return values
    # to LROPoller from azure.core. However, this change is not applied to local endpoints/deployments yet. This
    # function gracefully handles both values.
    return LongRunningOperation(cli_ctx)(maybe_lro) if isinstance(maybe_lro, LROPoller) else maybe_lro


def telemetry_log_info(info: Dict):
    # This is for logging any information except error.
    # e.g. creating a "Model" and want to log what kind of model is being used, custom, ml_flow etc
    # changing the property name 'ml.cli.info' will not show up in AzCLI telemetry as this is in GDPR allow list
    custom_properties_info = {}
    custom_properties_info["ml.cli.info"] = json.dumps(info)
    add_extension_event("ml", custom_properties_info)


def get_cloud_suffix_from_url(portal_url):
    """Get the suffix from portal url

    :param portal_url: the cloud endpoint to hit the azure portal
    :return: the suffix for the cloud
    """
    return ".".join(portal_url.split(".")[2:]).replace("/", "")


def get_registry_discovery_url(cloud_name, cloud_suffix):
    """Get or generate the registry discovery url

    :param cloud: configuration of the cloud to get the registry_discovery_url from
    :param cloud_suffix: the suffix to use for the cloud, in the case that the registry_discovery_url must be generated
    :return: string of discovery url
    """
    registry_discovery_region = environ.get(
        ArmConstants.REGISTRY_DISCOVERY_REGION_ENV_NAME,
        cloud_name.lower() + ArmConstants.REGISTRY_DISCOVERY_DEFAULT_REGION,
    )

    registry_discovery_region_url = "https://{}.api.azureml.{}/".format(registry_discovery_region, cloud_suffix)
    return environ.get(ArmConstants.REGISTRY_ENV_URL, registry_discovery_region_url)


def _get_ml_client_for_workspace(cmd, asset_params, resource_group, workspace_name=None):
    """Private function to get the ML Client workspace
    for promoting asset to registry

    :param asset_params: Dict of params that we get from the path
    :type asset_params: Dict[str,str]
    :param resource_group: Default resource group name
    :type resource_group: str
    :param workspace_name: Default workspace name
    :type workspace_name: str
    """
    workspace_name = asset_params.get("workspace_name", workspace_name)
    resource_group_name = asset_params.get("resource_group", resource_group)
    if workspace_name and resource_group_name:
        ml_client, _ = get_ml_client(
            cli_ctx=cmd.cli_ctx,
            resource_group_name=resource_group_name,
            workspace_name=workspace_name,
        )
        return ml_client
    msg = "Please provide a valid workspace name"
    raise ValidationException(
        message=msg,
        no_personal_data_message=msg,
        target=ErrorTarget.ASSET,
        error_category=ErrorCategory.USER_ERROR,
        error_type=ValidationErrorType.RESOURCE_NOT_FOUND,
    )


def _parse_registered_asset_path(asset_path: str, assetType: AzureMLResourceType = None) -> Dict[str, str]:
    """Extracts resource group, workspace name, asset name and
    model version from specific path. This is mainly used to promote
    registered asset to registry

    :param asset_path: Asset path
    :type asset_path: str
    Examples of valid path format:
    azureml://subscriptions/<subscriptionID>/resourcegroup/<resourceGroupName>/assets/<asset-name>/
    versions/<asset-version>
    azureml://resourcegroup/<resourceGroupName>/assets/<asset-name>/versions/<asset-version>
    azureml://assets/<asset-name>/versions/<asset-version>
    """
    asset_arm_id_match = re.match(ASSET_ARM_ID_REGEX_FORMAT, asset_path)
    if asset_arm_id_match:
        return {
            "resource_group": asset_arm_id_match.group(2),
            "workspace_name": asset_arm_id_match.group(3),
            "asset_name": asset_arm_id_match.group(5),
            "asset_version": asset_arm_id_match.group(6),
            "match_type": "asset_arm_id_match",
        }
    asset_id_match = re.match(ASSET_ID_REGEX_FORMAT, path)
    if asset_id_match:
        return {
            "resource_group": asset_id_match.group(2),
            "workspace_name": asset_id_match.group(3),
            "asset_name": asset_id_match.group(5),
            "asset_version": asset_id_match.group(6),
            "match_type": "asset_id_match",
        }
    resource_group_id_match = re.match(ASSET_ID_RESOURCE_REGEX_FORMAT, asset_path)
    if resource_group_id_match:
        return {
            "resource_group": resource_group_id_match.group(1),
            "workspace_name": resource_group_id_match.group(2),
            "asset_name": resource_group_id_match.group(4),
            "asset_version": resource_group_id_match.group(5),
            "match_type": "resource_group_id_match",
        }
    asset_regex_match = None
    if assetType == AzureMLResourceType.MODEL:
        asset_regex_match = re.match(MODEL_ID_REGEX_FORMAT, asset_path)
    elif assetType == AzureMLResourceType.DATA:
        asset_regex_match = re.match(DATA_ID_REGEX_FORMAT, asset_path)
    if asset_regex_match:
        return {
            "asset_name": asset_regex_match.group(1),
            "asset_version": asset_regex_match.group(2),
            "match_type": "asset_regex_match",
        }
    msg = "Unsupported `asset_path` value for asset promotion"
    raise ValidationException(
        message=msg,
        no_personal_data_message=msg,
        error_type=ValidationErrorType.INVALID_VALUE,
        error_category=ErrorCategory.USER_ERROR,
        target=ErrorTarget.ASSET,
    )


def modify_sys_path_for_rslex_mount(allow_rslex_not_installed: bool = False):
    # prepend sys.path
    # so that imports from azureml.dataprep.rslex refer to the one installed with az ml extension
    def _get_python_path():
        # __file__ /opt/az/extensions/ml/azext_mlv2/manual/custom/utils.py
        # returns  /opt/az/extensions/ml
        return path.normpath(path.join(__file__, *[pardir] * 4))

    python_path = _get_python_path()
    if (not allow_rslex_not_installed) and (
        not path.exists(path.join(python_path, "azureml", "dataprep", "rslex_fuse_subprocess_wrapper"))
    ):
        raise ImportError(
            "Cannot mount since `azureml-dataprep-rslex` is not installed. "
            + "It is required for `az ml data mount` and `az ml data mount` to work."
            + "To install, run: `$ pip install --target $(eval echo $(az extension show -n ml "
            + "--query path)) azureml-dataprep-rslex`"
        )
    sys.path = [python_path] + sys.path
