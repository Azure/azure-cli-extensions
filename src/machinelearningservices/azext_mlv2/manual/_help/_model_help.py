# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
#
# Code generated by Microsoft (R) AutoRest Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is
# regenerated.
# --------------------------------------------------------------------------
from knack.help_files import helps


def get_model_help():
    helps[
        "ml model"
    ] = """
        type: group
        short-summary: Manage Azure ML models.
        long-summary: >
            Azure ML models consist of the binary file(s) that represent a machine learning
            model and any corresponding metadata.  These models can be used in endpoint
            deployments for real-time and batch inference.
    """
    helps[
        "ml model create"
    ] = """
        type: command
        short-summary: Create a model.
        long-summary: >
            Models can be created from a local file, local directory, datastore or job outputs. The created model will be
            tracked in the workspace/registry under the specified name and version. If you are using a registry, replace `--workspace-name my-workspace` with the `--registry-name <registry-name>` option.
        examples:
        - name: Create a model from a YAML specification file
          text: az ml model create --file model.yml --resource-group my-resource-group --workspace-name my-workspace
        - name: Create a model from a local folder using command options
          text: az ml model create --name my-model --version 1 --path ./my-model --resource-group my-resource-group --workspace-name my-workspace
        - name: Create a model using mlflow run URI format 'runs:/<run-id>/<path-to-model-relative-to-the-root-of-the-artifact-location>' and command options
          text: az ml model create --name my-model --version 1 --path runs:/c42d2507-4953-4a7c-a4c1-2b5bfe0ac64e/model/ --type mlflow_model --resource-group my-resource-group --workspace-name my-workspace
        - name: Create a model from a named job output using azureml job URI format 'azureml://jobs/<job-name>/outputs/<named-output>/paths/<path-to-model-relative-to-the-named-output-location>' and command options. The default named output is artifacts
          text: az ml model create --name my-model --version 1 --path azureml://jobs/c42d2507-4953-4a7c-a4c1-2b5bfe0ac64e/outputs/artifacts/paths/model/ --resource-group my-resource-group --workspace-name my-workspace
        - name: Create a model from a datastore 'azureml://datastores/<datastore-name>/paths/<path-to-model-relative-to-the-root-of-the-datastore-location>' using command options
          text: az ml model create --name my-model --version 1 --path azureml://datastores/myblobstore/paths/models/cifar10/cifar.pt --resource-group my-resource-group --workspace-name my-workspace
    """
    helps[
        "ml model show"
    ] = """
        type: command
        short-summary: Show details for a model in a workspace/registry. If you are using a registry, replace `--workspace-name my-workspace` with the `--registry-name <registry-name>` option.
        examples:
        - name: Show details for a model with the specified name and version
          text: az ml model show --name my-model --version 1 --resource-group my-resource-group --workspace-name my-workspace
    """
    helps[
        "ml model download"
    ] = """
        type: command
        short-summary: Download all model-related files.
        long-summary: The files will be downloaded into a folder named after the model's name. If you are using a registry, replace `--workspace-name my-workspace` with the `--registry-name <registry-name>` option.
        examples:
        - name: Download a model with the specified name and version
          text: az ml model download --name my-model --version 1 --resource-group my-resource-group --workspace-name my-workspace
        - name: Download a model with the specified name and version, into a specified local path
          text: az ml model download --name my-model --version 1  --download-path local_path --resource-group my-resource-group --workspace-name my-workspace

    """

    helps[
        "ml model list"
    ] = """
        type: command
        short-summary: List models in a workspace/registry. If you are using a registry, replace `--workspace-name my-workspace` with the `--registry-name <registry-name>` option.
        examples:
        - name: List all the models in a workspace
          text: az ml model list --resource-group my-resource-group --workspace-name my-workspace
        - name: List all the model versions for the specified name in a workspace
          text: az ml model list --name my-model --resource-group my-resource-group --workspace-name my-workspace
        - name: List all the models in a workspace using --query argument to execute a JMESPath query on the results of commands.
          text: az ml model list --query \"[].{Name:name}\"  --output table --resource-group my-resource-group --workspace-name my-workspace
    """
    helps[
        "ml model update"
    ] = """
        type: command
        short-summary: Update a model in a workspace/registry.
        long-summary: >
            The 'description', and 'tags' properties can be updated. If you are using a registry, replace `--workspace-name my-workspace` with the `--registry-name <registry-name>` option.
        examples:
        - name: Update a model's flavors
          text: az ml model update --name my-model --version 1 --set flavors.python_function.python_version=3.8 --resource-group my-resource-group --workspace-name my-workspace
    """
    helps[
        "ml model archive"
    ] = """
        type: command
        short-summary: Archive a model.
        long-summary: >
            Archiving a model will hide it by default from list queries (`az ml model list`). You
            can still continue to reference and use an archived model in your workflows.
            You can archive either a model container or a specific model version. Archiving a
            model container will archive all versions of the model under that given name.
            You can restore an archived model using `az ml model restore`. If the entire
            model container is archived, you cannot restore individual versions of the model -
            you will need to restore the model container.
        examples:
        - name: Archive a model container (archives all versions of that model)
          text: az ml model archive --name my-model --resource-group my-resource-group --workspace-name my-workspace
        - name: Archive a specific model version
          text: az ml model archive --name my-model --version 1 --resource-group my-resource-group --workspace-name my-workspace
    """
    helps[
        "ml model restore"
    ] = """
        type: command
        short-summary: Restore an archived model.
        long-summary: >
            When an archived model is restored, it will no longer be hidden from list queries (`az ml model list`).
            If an entire model container is archived, you can restore that archived container. This
            will restore all versions of the model under that given name. You cannot restore only a
            specific model version if the entire model container is archived - you will need to
            restore the entire container. If only an individual model version was archived, you can
            restore that specific version.
        examples:
        - name: Restore an archived model container (restores all versions of that model)
          text: az ml model restore --name my-model --resource-group my-resource-group --workspace-name my-workspace
        - name: Restore a specific archived model version
          text: az ml model restore --name my-model --version 1 --resource-group my-resource-group --workspace-name my-workspace
    """
    helps[
        "ml model share"
    ] = """
        type: command
        short-summary: Share a specific model from workspace to registry.
        long-summary: >
          Copy an existing model from a workspace to a registry for cross-workspace reuse.
        examples:
        - name: Share an existing environment from workspace to registry
          text: az ml model share --name my-model --version my-version --resource-group my-resource-group --workspace-name my-workspace --share-with-name new-name-in-registry --share-with-version new-version-in-registry --registry-name my-registry
    """
    helps[
        "ml model package"
    ] = """
        type: command
        short-summary: Package a model into an environment.
        long-summary: >
            When a model is packaged, an environment with all the dependencies is created.
        examples:
        - name: Package a model with the specified name and version
          text: az ml model package --name my-model --version my-version --resource-group my-resource-group --workspace-name my-workspace --file my-package.yml
    """
